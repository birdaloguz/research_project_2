{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#df_ratings = pd.read_csv('ml-20m/ratings.csv', skiprows=[0], names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]).drop(columns=['timestamp']).head(1000000)\n",
    "df_ratings = pd.read_csv('ml-1m/ratings.dat', names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"],\n",
    "            header=None, sep='::', engine='python')\n",
    "matrix_df = df_ratings.pivot(index='movie_id', columns='user_id', values='rating').fillna(0).astype(bool).astype(int)\n",
    "\n",
    "#idx to id and reverse dicts\n",
    "c=0\n",
    "hashmap = {} \n",
    "reverse_hashmap = {}\n",
    "for i in matrix_df.index.tolist():\n",
    "    hashmap[c] = i\n",
    "    reverse_hashmap[i] = c\n",
    "    c+=1\n",
    "\n",
    "#get first nonzero elements for validation\n",
    "validation_movies = matrix_df.ne(0).idxmax()\n",
    "\n",
    "#make validation movies unrated\n",
    "for index, row in validation_movies.items():\n",
    "    matrix_df[index][row] = 0\n",
    "\n",
    "#get second nonzero elements for validation\n",
    "validation_movies2 = matrix_df.ne(0).idxmax()\n",
    "\n",
    "#make validation movies rated\n",
    "for index, row in validation_movies.items():\n",
    "    matrix_df[index][row] = 1\n",
    "\n",
    "#make validation movies2 unrated\n",
    "for index, row in validation_movies2.items():\n",
    "    matrix_df[index][row] = 0\n",
    "    \n",
    "um_matrix = scipy.sparse.csr_matrix(matrix_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of movies that each user rated\n",
    "user_hists = []\n",
    "for user in matrix_df:\n",
    "    a = [i for i, e in enumerate(matrix_df[user].tolist()) if e != 0]\n",
    "    user_hists.append(a)\n",
    "\n",
    "matrix_df= matrix_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "\n",
    "f = len(matrix_df[0])\n",
    "t = AnnoyIndex(f, \"angular\")  # Length of item vector that will be indexed\n",
    "for i in range(0, len(matrix_df)):\n",
    "    v = matrix_df[i]\n",
    "    t.add_item(i, v)\n",
    "\n",
    "t.build(1000) # 10 trees\n",
    "t.save('annoy.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AnnoyIndex(f)\n",
    "t.load('annoy.ann') # super fast, will just mmap the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#for each user get average distance of the movies that user rated to retrieve top k movies to recommend\n",
    "avg_dict = {}\n",
    "for index, user in enumerate(user_hists[:10]):\n",
    "    print(index)\n",
    "    user_dict={}\n",
    "    for movie in user:\n",
    "        indices, distances = t.get_nns_by_item(movie, len(matrix_df), include_distances=True) # will find the all distances\n",
    "        for idx, i in enumerate(indices):\n",
    "            if i not in user_dict:\n",
    "                user_dict[i]=distances[idx]\n",
    "            else:\n",
    "                user_dict[i]+=distances[idx]\n",
    "    avg_dict[index]=dict(sorted(user_dict.items(), key=lambda x: x[1]))\n",
    "    for m in user_hists[index]:\n",
    "        del avg_dict[index][m]\n",
    "    avg_dict[index] = {k: avg_dict[index][k] for k in list(avg_dict[index])[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "recall = 0\n",
    "for user in avg_dict:\n",
    "    if reverse_hashmap[validation_movies[user+1]] in avg_dict[user]: \n",
    "        recall+=1\n",
    "print(recall)\n",
    "recall=recall/len(user_hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for key in avg_dict:\n",
    "    results.append(list(avg_dict[key].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(rs):\n",
    "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "\n",
    "for i in range(0, len(results)):\n",
    "    for x in range(0,len(results[i])):\n",
    "        if results[i][x]==reverse_hashmap[validation_movies[i+1]]:\n",
    "            results[i][x]=1\n",
    "        else:\n",
    "            results[i][x]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr = mean_reciprocal_rank(results)\n",
    "ndcg=0\n",
    "for i in results:\n",
    "    ndcg+=ndcg_at_k(i, 10)\n",
    "ndcg=ndcg/len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(recall)\n",
    "print(mrr)\n",
    "print(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
